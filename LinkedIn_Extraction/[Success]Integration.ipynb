{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Creekside Partners and saved results to Creekside_Partners_linkedin_links.json\n",
      "Processed Gordian Capital Singapore Pte Ltd and saved results to Gordian_Capital_Singapore_Pte_Ltd_linkedin_links.json\n",
      "Processed Brown Financial Advisors and saved results to Brown_Financial_Advisors_linkedin_links.json\n",
      "Processed NCP Inc. and saved results to NCP_Inc._linkedin_links.json\n",
      "Processed SW Investment Management LLC and saved results to SW_Investment_Management_LLC_linkedin_links.json\n",
      "Processed Centennial Bank AR and saved results to Centennial_Bank_AR_linkedin_links.json\n",
      "Processed Mendon Capital Advisors Corp and saved results to Mendon_Capital_Advisors_Corp_linkedin_links.json\n",
      "Processed Pensioenfonds Rail & OV and saved results to Pensioenfonds_Rail_&_OV_linkedin_links.json\n",
      "Processed Strategic Investment Solutions Inc. IL and saved results to Strategic_Investment_Solutions_Inc._IL_linkedin_links.json\n",
      "Processed University of Texas Texas AM Investment Management Co. and saved results to University_of_Texas_Texas_AM_Investment_Management_Co._linkedin_links.json\n",
      "Processed SRN Advisors LLC and saved results to SRN_Advisors_LLC_linkedin_links.json\n",
      "Processed Cowen Investment Management LLC and saved results to Cowen_Investment_Management_LLC_linkedin_links.json\n",
      "Processed Maven Securities LTD and saved results to Maven_Securities_LTD_linkedin_links.json\n",
      "Processed Gibson Wealth Advisors LLC and saved results to Gibson_Wealth_Advisors_LLC_linkedin_links.json\n",
      "Processed RiverFront Investment Group LLC and saved results to RiverFront_Investment_Group_LLC_linkedin_links.json\n",
      "Processed Heritage Oak Wealth Advisors LLC and saved results to Heritage_Oak_Wealth_Advisors_LLC_linkedin_links.json\n",
      "Processed Kestra Investment Management LLC and saved results to Kestra_Investment_Management_LLC_linkedin_links.json\n",
      "Processed Sycomore Asset Management and saved results to Sycomore_Asset_Management_linkedin_links.json\n",
      "Error searching for Birmingham Capital Management Co. Inc. AL: HTTP Error 429: Too Many Requests\n",
      "Processed Birmingham Capital Management Co. Inc. AL and saved results to Birmingham_Capital_Management_Co._Inc._AL_linkedin_links.json\n",
      "Error searching for Farmers National Bank: HTTP Error 429: Too Many Requests\n",
      "Processed Farmers National Bank and saved results to Farmers_National_Bank_linkedin_links.json\n",
      "Error searching for Souders Financial Advisors: HTTP Error 429: Too Many Requests\n",
      "Processed Souders Financial Advisors and saved results to Souders_Financial_Advisors_linkedin_links.json\n",
      "Error searching for Logos Global Management LP: HTTP Error 429: Too Many Requests\n",
      "Processed Logos Global Management LP and saved results to Logos_Global_Management_LP_linkedin_links.json\n",
      "Error searching for Clearbridge Investments LLC: HTTP Error 429: Too Many Requests\n",
      "Processed Clearbridge Investments LLC and saved results to Clearbridge_Investments_LLC_linkedin_links.json\n",
      "Error searching for Carrera Capital Advisors: HTTP Error 429: Too Many Requests\n",
      "Processed Carrera Capital Advisors and saved results to Carrera_Capital_Advisors_linkedin_links.json\n",
      "Error searching for New Wave Wealth Advisors LLC: HTTP Error 429: Too Many Requests\n",
      "Processed New Wave Wealth Advisors LLC and saved results to New_Wave_Wealth_Advisors_LLC_linkedin_links.json\n",
      "Error searching for Dana Investment Advisors Inc.: HTTP Error 429: Too Many Requests\n",
      "Processed Dana Investment Advisors Inc. and saved results to Dana_Investment_Advisors_Inc._linkedin_links.json\n",
      "Error searching for New Century Financial Group LLC: HTTP Error 429: Too Many Requests\n",
      "Processed New Century Financial Group LLC and saved results to New_Century_Financial_Group_LLC_linkedin_links.json\n",
      "Error searching for Custom Portfolio Group LLC: HTTP Error 429: Too Many Requests\n",
      "Processed Custom Portfolio Group LLC and saved results to Custom_Portfolio_Group_LLC_linkedin_links.json\n",
      "Error searching for KPP Advisory Services LLC: HTTP Error 429: Too Many Requests\n",
      "Processed KPP Advisory Services LLC and saved results to KPP_Advisory_Services_LLC_linkedin_links.json\n",
      "Processed Teachers Retirement System of The State of Kentucky and saved results to Teachers_Retirement_System_of_The_State_of_Kentucky_linkedin_links.json\n",
      "Processed Allianz Investment Management U.S. LLC and saved results to Allianz_Investment_Management_U.S._LLC_linkedin_links.json\n",
      "Processed Wealthquest Corp and saved results to Wealthquest_Corp_linkedin_links.json\n",
      "Processed BRIGHT VALLEY CAPITAL Ltd and saved results to BRIGHT_VALLEY_CAPITAL_Ltd_linkedin_links.json\n",
      "Processed Ariadne Wealth Management LP and saved results to Ariadne_Wealth_Management_LP_linkedin_links.json\n",
      "Processed Founders Financial Alliance LLC and saved results to Founders_Financial_Alliance_LLC_linkedin_links.json\n",
      "Processed SPX Gestao de Recursos Ltda and saved results to SPX_Gestao_de_Recursos_Ltda_linkedin_links.json\n",
      "Processed Delphi Management Inc. MA and saved results to Delphi_Management_Inc._MA_linkedin_links.json\n",
      "Processed Aristides Capital LLC and saved results to Aristides_Capital_LLC_linkedin_links.json\n",
      "Processed Somnio Financial Group LLC and saved results to Somnio_Financial_Group_LLC_linkedin_links.json\n",
      "Processed Orleans Capital Management Corp LA and saved results to Orleans_Capital_Management_Corp_LA_linkedin_links.json\n",
      "Processed Troy Asset Management Ltd and saved results to Troy_Asset_Management_Ltd_linkedin_links.json\n",
      "Processed PVG Asset Management Corp and saved results to PVG_Asset_Management_Corp_linkedin_links.json\n",
      "Processed Cypress Capital LLC and saved results to Cypress_Capital_LLC_linkedin_links.json\n",
      "Processed Aurora Investment Counsel and saved results to Aurora_Investment_Counsel_linkedin_links.json\n",
      "Processed Cetera Investment Advisers and saved results to Cetera_Investment_Advisers_linkedin_links.json\n",
      "Processed Aldebaran Financial Inc. and saved results to Aldebaran_Financial_Inc._linkedin_links.json\n",
      "Processed Kanen Wealth Management LLC and saved results to Kanen_Wealth_Management_LLC_linkedin_links.json\n",
      "Processed KGH Ltd and saved results to KGH_Ltd_linkedin_links.json\n",
      "Processed LHM Inc. and saved results to LHM_Inc._linkedin_links.json\n",
      "Processed 3Chopt Investment Partners LLC and saved results to 3Chopt_Investment_Partners_LLC_linkedin_links.json\n",
      "Processed McGinn Penninger Investment Management Inc. and saved results to McGinn_Penninger_Investment_Management_Inc._linkedin_links.json\n",
      "Processed SPC Financial Inc. and saved results to SPC_Financial_Inc._linkedin_links.json\n",
      "Processed Heartland Bank & Trust Co and saved results to Heartland_Bank_&_Trust_Co_linkedin_links.json\n",
      "Processed Greenvale Capital LLP and saved results to Greenvale_Capital_LLP_linkedin_links.json\n",
      "Processed Advisory Alpha LLC and saved results to Advisory_Alpha_LLC_linkedin_links.json\n",
      "Processed Ted Buchan & Co and saved results to Ted_Buchan_&_Co_linkedin_links.json\n",
      "Processed Graham Capital Wealth Management LLC and saved results to Graham_Capital_Wealth_Management_LLC_linkedin_links.json\n",
      "Processed Granite Bay Wealth Management LLC and saved results to Granite_Bay_Wealth_Management_LLC_linkedin_links.json\n",
      "Processed IMS Capital Management and saved results to IMS_Capital_Management_linkedin_links.json\n",
      "Processed Regency Capital Management Inc. DE and saved results to Regency_Capital_Management_Inc._DE_linkedin_links.json\n",
      "Processed Stonepine Capital Management LLC and saved results to Stonepine_Capital_Management_LLC_linkedin_links.json\n",
      "Processed Truist Financial Corp and saved results to Truist_Financial_Corp_linkedin_links.json\n",
      "Processed Nantahala Capital Management LLC and saved results to Nantahala_Capital_Management_LLC_linkedin_links.json\n",
      "Processed Pathway Financial Advisers LLC and saved results to Pathway_Financial_Advisers_LLC_linkedin_links.json\n",
      "Processed HFG Wealth Management LLC and saved results to HFG_Wealth_Management_LLC_linkedin_links.json\n",
      "Processed Novo Holdings A S and saved results to Novo_Holdings_A_S_linkedin_links.json\n",
      "Processed Next Capital Management LLC and saved results to Next_Capital_Management_LLC_linkedin_links.json\n",
      "Processed Senator Investment Group LP and saved results to Senator_Investment_Group_LP_linkedin_links.json\n",
      "Processed Garde Capital Inc. and saved results to Garde_Capital_Inc._linkedin_links.json\n",
      "Processed HWG Holdings LP and saved results to HWG_Holdings_LP_linkedin_links.json\n",
      "Processed Point72 Asset Management L.P. and saved results to Point72_Asset_Management_L.P._linkedin_links.json\n",
      "Processed Old North State Trust LLC and saved results to Old_North_State_Trust_LLC_linkedin_links.json\n",
      "Processed Fiera Capital Corp and saved results to Fiera_Capital_Corp_linkedin_links.json\n",
      "Processed EP Wealth Advisors LLC and saved results to EP_Wealth_Advisors_LLC_linkedin_links.json\n",
      "Processed Hershey Financial Advisers LLC and saved results to Hershey_Financial_Advisers_LLC_linkedin_links.json\n",
      "Processed Chase Investment Counsel Corp and saved results to Chase_Investment_Counsel_Corp_linkedin_links.json\n",
      "Processed Brown Shipley& Co Ltd and saved results to Brown_Shipley&_Co_Ltd_linkedin_links.json\n",
      "Processed Kimelman & Baird LLC and saved results to Kimelman_&_Baird_LLC_linkedin_links.json\n",
      "Processed Brandes Investment Partners LP and saved results to Brandes_Investment_Partners_LP_linkedin_links.json\n",
      "Processed Lynx1 Capital Management LP and saved results to Lynx1_Capital_Management_LP_linkedin_links.json\n",
      "Processed B. Riley Wealth Advisors Inc. and saved results to B._Riley_Wealth_Advisors_Inc._linkedin_links.json\n",
      "Processed Connective Capital Management LLC and saved results to Connective_Capital_Management_LLC_linkedin_links.json\n",
      "Processed CMG Global Holdings LLC and saved results to CMG_Global_Holdings_LLC_linkedin_links.json\n",
      "Processed Newport Capital Group LLC and saved results to Newport_Capital_Group_LLC_linkedin_links.json\n",
      "Processed Gateway Wealth Partners LLC and saved results to Gateway_Wealth_Partners_LLC_linkedin_links.json\n",
      "Processed Perceptive Advisors LLC and saved results to Perceptive_Advisors_LLC_linkedin_links.json\n",
      "Processed Traction Financial Partners LLC and saved results to Traction_Financial_Partners_LLC_linkedin_links.json\n",
      "Processed Core Alternative Capital and saved results to Core_Alternative_Capital_linkedin_links.json\n",
      "Processed Ironwood Investment Management LLC and saved results to Ironwood_Investment_Management_LLC_linkedin_links.json\n",
      "Processed Kampmann Melissa S. and saved results to Kampmann_Melissa_S._linkedin_links.json\n",
      "Processed Wallace Capital Management Inc. and saved results to Wallace_Capital_Management_Inc._linkedin_links.json\n",
      "Processed Saratoga Research & Investment Management and saved results to Saratoga_Research_&_Investment_Management_linkedin_links.json\n",
      "Processed Ecofi Investissements SA and saved results to Ecofi_Investissements_SA_linkedin_links.json\n",
      "Processed Seaport Global Advisors LLC and saved results to Seaport_Global_Advisors_LLC_linkedin_links.json\n",
      "Processed Capital Impact Advisors LLC and saved results to Capital_Impact_Advisors_LLC_linkedin_links.json\n",
      "Processed Progeny 3 Inc. and saved results to Progeny_3_Inc._linkedin_links.json\n",
      "Processed Second Line Capital LLC and saved results to Second_Line_Capital_LLC_linkedin_links.json\n",
      "Processed Covington Investment Advisors Inc. and saved results to Covington_Investment_Advisors_Inc._linkedin_links.json\n",
      "Processed Teewinot Capital Advisers L.L.C. and saved results to Teewinot_Capital_Advisers_L.L.C._linkedin_links.json\n",
      "Processed Invst LLC and saved results to Invst_LLC_linkedin_links.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from pymongo import MongoClient\n",
    "import anthropic\n",
    "from googlesearch import search\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Get MongoDB URI and Anthropic API key from .env file\n",
    "mongodb_uri = os.getenv('13F_MongoDB_URI')\n",
    "Anthropic_Key = os.getenv(\"13F_Anthropic_Key\")\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(mongodb_uri)\n",
    "db = client['13f_filings']\n",
    "collection = db['investment_firms']\n",
    "\n",
    "# Initialize Anthropic client\n",
    "anthropic_client = anthropic.Anthropic(api_key=Anthropic_Key)\n",
    "\n",
    "def search_company(company_name):\n",
    "    query = f\"{company_name} LLC site:linkedin.com\"\n",
    "    search_results = []\n",
    "    \n",
    "    try:\n",
    "        for j in search(query, tld=\"co.in\", num=10, stop=10, pause=2):\n",
    "            search_results.append(j)\n",
    "    except Exception as e:\n",
    "        print(f\"Error searching for {company_name}: {str(e)}\")\n",
    "    \n",
    "    json_results = {\n",
    "        \"company\": company_name,\n",
    "        \"results\": search_results\n",
    "    }\n",
    "    \n",
    "    return json.dumps(json_results, indent=2)\n",
    "\n",
    "def extract_relevant_links(search_results):\n",
    "    system_prompt = \"\"\"\n",
    "    You will be provided with a list of LinkedIn URLs for a company. Your task is to identify and list the URLs that are specifically about people associated with the company.\n",
    "\n",
    "    After your analysis, provide your response in the following format:\n",
    "\n",
    "    <answer>\n",
    "    [List the urls of LinkedIn profiles here, one per line. If there are no relevant profiles, state \"No relevant LinkedIn profiles found.\"]\n",
    "    </answer>\n",
    "\n",
    "    Important notes:\n",
    "    - Only include LinkedIn profile URLs.\n",
    "    - If there are multiple relevant profiles, list all of them in a comma separated format.\n",
    "    - If no relevant profiles are found, simply state \"No relevant LinkedIn profiles found.\" in your answer.\n",
    "    - Do not include any explanations or additional commentary in your answer, just the list of URLs or the \"No profiles found\" statement.\n",
    "    \"\"\"\n",
    "\n",
    "    message = anthropic_client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20240620\",\n",
    "        max_tokens=1000,\n",
    "        temperature=0,\n",
    "        system=system_prompt,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": f\"{search_results}\"\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return message.content[0].text\n",
    "\n",
    "def remove_answer_tag(text):\n",
    "    return re.sub(r'</?answer>', '', text)\n",
    "\n",
    "def parse_comma_separated_string(input_string):\n",
    "    items = input_string.split(',')\n",
    "    cleaned_items = [item.strip() for item in items]\n",
    "    result = [item for item in cleaned_items if item]\n",
    "    return result\n",
    "\n",
    "def process_company(company_name):\n",
    "    search_results = search_company(company_name)\n",
    "    extracted_urls = extract_relevant_links(search_results)\n",
    "    cleaned_extracted_urls = remove_answer_tag(extracted_urls)\n",
    "    list_of_extracted_urls = parse_comma_separated_string(cleaned_extracted_urls)\n",
    "    \n",
    "    return list_of_extracted_urls\n",
    "\n",
    "def main():\n",
    "    # Extract firm names from the collection\n",
    "    firm_names = [doc['Firm Name'] for doc in collection.find({}, {'Firm Name': 1, '_id': 0}) if 'Firm Name' in doc]\n",
    "\n",
    "    # Process each company and create JSON files\n",
    "    for company_name in firm_names:\n",
    "        linkedin_links = process_company(company_name)\n",
    "        \n",
    "        # Create a JSON file for each company\n",
    "        filename = f\"{company_name.replace(' ', '_')}_linkedin_links.json\"\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump({company_name: linkedin_links}, f, indent=2)\n",
    "        \n",
    "        print(f\"Processed {company_name} and saved results to {filename}\")\n",
    "\n",
    "    # Close the MongoDB connection\n",
    "    client.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duck Duck Go Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RatelimitException",
     "evalue": "https://duckduckgo.com/ 202 Ratelimit",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRatelimitException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 118\u001b[0m\n\u001b[0;32m    115\u001b[0m     client\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 118\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 105\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# Process each company and create JSON files\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m company_name \u001b[38;5;129;01min\u001b[39;00m firm_names:\n\u001b[1;32m--> 105\u001b[0m     linkedin_links \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_company\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompany_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;66;03m# Create a JSON file for each company\u001b[39;00m\n\u001b[0;32m    108\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompany_name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_linkedin_links.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[2], line 92\u001b[0m, in \u001b[0;36mprocess_company\u001b[1;34m(company_name)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_company\u001b[39m(company_name):\n\u001b[1;32m---> 92\u001b[0m     search_results \u001b[38;5;241m=\u001b[39m \u001b[43msearch_company\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompany_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m     extracted_urls \u001b[38;5;241m=\u001b[39m extract_relevant_links(search_results)\n\u001b[0;32m     94\u001b[0m     cleaned_extracted_urls \u001b[38;5;241m=\u001b[39m remove_answer_tag(extracted_urls)\n",
      "Cell \u001b[1;32mIn[2], line 28\u001b[0m, in \u001b[0;36msearch_company\u001b[1;34m(company_name)\u001b[0m\n\u001b[0;32m     25\u001b[0m search_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompany_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m site:linkedin.com\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m DDGS() \u001b[38;5;28;01mas\u001b[39;00m ddgs:\n\u001b[1;32m---> 28\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mddgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m(\u001b[49m\u001b[43msearch_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     30\u001b[0m json_results \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompany\u001b[39m\u001b[38;5;124m\"\u001b[39m: company_name,\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m\"\u001b[39m: []\n\u001b[0;32m     33\u001b[0m }\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "File \u001b[1;32mc:\\Users\\josep\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\duckduckgo_search\\duckduckgo_search.py:156\u001b[0m, in \u001b[0;36mDDGS.text\u001b[1;34m(self, keywords, region, safesearch, timelimit, backend, max_results)\u001b[0m\n\u001b[0;32m    153\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlxml is not installed. Using backend=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapi\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 156\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_text_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeywords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafesearch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimelimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m backend \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    158\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_text_html(keywords, region, safesearch, timelimit, max_results)\n",
      "File \u001b[1;32mc:\\Users\\josep\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\duckduckgo_search\\duckduckgo_search.py:190\u001b[0m, in \u001b[0;36mDDGS._text_api\u001b[1;34m(self, keywords, region, safesearch, timelimit, max_results)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"DuckDuckGo text search. Query params: https://duckduckgo.com/params.\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \n\u001b[0;32m    173\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;124;03m    TimeoutException: Inherits from DuckDuckGoSearchException, raised for API request timeouts.\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m keywords, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeywords is mandatory\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 190\u001b[0m vqd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_vqd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeywords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m payload \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m\"\u001b[39m: keywords,\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkl\u001b[39m\u001b[38;5;124m\"\u001b[39m: region,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mex\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    201\u001b[0m }\n\u001b[0;32m    202\u001b[0m safesearch \u001b[38;5;241m=\u001b[39m safesearch\u001b[38;5;241m.\u001b[39mlower()\n",
      "File \u001b[1;32mc:\\Users\\josep\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\duckduckgo_search\\duckduckgo_search.py:118\u001b[0m, in \u001b[0;36mDDGS._get_vqd\u001b[1;34m(self, keywords)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_vqd\u001b[39m(\u001b[38;5;28mself\u001b[39m, keywords: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    117\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get vqd value for a search query.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 118\u001b[0m     resp_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_url\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://duckduckgo.com\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mq\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeywords\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _extract_vqd(resp_content, keywords)\n",
      "File \u001b[1;32mc:\\Users\\josep\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\duckduckgo_search\\duckduckgo_search.py:113\u001b[0m, in \u001b[0;36mDDGS._get_url\u001b[1;34m(self, method, url, params, content, data)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception_event\u001b[38;5;241m.\u001b[39mset()\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m202\u001b[39m, \u001b[38;5;241m301\u001b[39m, \u001b[38;5;241m403\u001b[39m):\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RatelimitException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresp\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresp\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Ratelimit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m DuckDuckGoSearchException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresp\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m return None. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontent\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRatelimitException\u001b[0m: https://duckduckgo.com/ 202 Ratelimit"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from pymongo import MongoClient\n",
    "from duckduckgo_search import DDGS\n",
    "import anthropic\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Get MongoDB URI and Anthropic API key from .env file\n",
    "mongodb_uri = os.getenv('13F_MongoDB_URI')\n",
    "Anthropic_Key = os.getenv(\"13F_Anthropic_Key\")\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(mongodb_uri)\n",
    "db = client['13f_filings']\n",
    "collection = db['investment_firms']\n",
    "\n",
    "# Initialize Anthropic client\n",
    "anthropic_client = anthropic.Anthropic(api_key=Anthropic_Key)\n",
    "\n",
    "def search_company(company_name):\n",
    "    search_query = f\"{company_name} site:linkedin.com\"\n",
    "    \n",
    "    with DDGS() as ddgs:\n",
    "        results = list(ddgs.text(search_query, max_results=5))\n",
    "    \n",
    "    json_results = {\n",
    "        \"company\": company_name,\n",
    "        \"results\": []\n",
    "    }\n",
    "    \n",
    "    for result in results:\n",
    "        json_results[\"results\"].append({\n",
    "            \"title\": result['title'],\n",
    "            \"url\": result['href'],\n",
    "            \"body\": result['body']\n",
    "        })\n",
    "    \n",
    "    return json.dumps(json_results, indent=2)\n",
    "\n",
    "def extract_relevant_links(search_results):\n",
    "    system_prompt = \"\"\"\n",
    "    You will be provided with information about various websites, including their names, links, and descriptions. Your task is to identify and list the names of websites that are specifically about people.\n",
    "\n",
    "    Carefully analyze the provided website information. For each website, determine if its primary focus is on a person or people. This could include biographical websites, personal blogs, or sites dedicated to public figures.\n",
    "\n",
    "    After your analysis, provide your response in the following format:\n",
    "\n",
    "    <answer>\n",
    "    [List the urls of websites about people here, one per line. If there are no such websites, state \"No websites about people found.\"]\n",
    "    </answer>\n",
    "\n",
    "    Important notes:\n",
    "    - Only include websites that are primarily about specific individuals or groups of people.\n",
    "    - If there are multiple relevant websites, list all of them in a comma separated format\n",
    "    - If no websites are about people, simply state \"No websites about people found.\" in your answer.\n",
    "    - Do not include any explanations or additional commentary in your answer, just the list of names or the \"No websites found\" statement.\n",
    "    \"\"\"\n",
    "\n",
    "    message = anthropic_client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20240620\",\n",
    "        max_tokens=1000,\n",
    "        temperature=0,\n",
    "        system=system_prompt,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": f\"{search_results}\"\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return message.content[0].text\n",
    "\n",
    "def remove_answer_tag(text):\n",
    "    return re.sub(r'</?answer>', '', text)\n",
    "\n",
    "def parse_comma_separated_string(input_string):\n",
    "    items = input_string.split(',')\n",
    "    cleaned_items = [item.strip() for item in items]\n",
    "    result = [item for item in cleaned_items if item]\n",
    "    return result\n",
    "\n",
    "def process_company(company_name):\n",
    "    search_results = search_company(company_name)\n",
    "    extracted_urls = extract_relevant_links(search_results)\n",
    "    cleaned_extracted_urls = remove_answer_tag(extracted_urls)\n",
    "    list_of_extracted_urls = parse_comma_separated_string(cleaned_extracted_urls)\n",
    "    \n",
    "    return list_of_extracted_urls\n",
    "\n",
    "def main():\n",
    "    # Extract firm names from the collection\n",
    "    firm_names = [doc['Firm Name'] for doc in collection.find({}, {'Firm Name': 1, '_id': 0}) if 'Firm Name' in doc]\n",
    "\n",
    "    # Process each company and create JSON files\n",
    "    for company_name in firm_names:\n",
    "        linkedin_links = process_company(company_name)\n",
    "        \n",
    "        # Create a JSON file for each company\n",
    "        filename = f\"{company_name.replace(' ', '_')}_linkedin_links.json\"\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump({company_name: linkedin_links}, f, indent=2)\n",
    "        \n",
    "        print(f\"Processed {company_name} and saved results to {filename}\")\n",
    "\n",
    "    # Close the MongoDB connection\n",
    "    client.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
